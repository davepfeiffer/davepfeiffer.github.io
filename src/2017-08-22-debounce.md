---

layout: post
title: "Debouncing Theory"
date: 2017-08-22 00:00:00

---

While I was working with embedded systems, the issue of button debouncing in software came up regularly. In order to implement debouncing schemes with confidence, I compiled some semi-formal notes on debouncing/sampling theory in my spare time. I polished the notes up and posted them here in the off chance that someone will find them useful (maybe my future self).

---

# General Theory

__Problem:__ Input devices are physical/analog components and will '_bounce_'
between states during a transition causing inputs to be misinterpreted.

This bouncing is a result of:

- Capacitance causing the signal to linger in a meta-stable state (midway between logical 0 and 1) [1]

- Physical characteristics of the button causing contacts to rebound [2]

These behaviors depend on so many variables that it's infeasible to create an accurate input bounce model for each device. As a result, polling bouncy signals will always have to make sacrifices. 

Fortunately--much like the digital world pretends analog signals are either on or off--an abstraction model can be set up to make handling bounce easier. The only contracts needed for such a model are:

- `input width` -- the minimum period an input must remain in a state in order to be recognized

- `input latency` -- the maximum amount of time between an input's state changing and the software seeing said change

The goal is to minimize both input width and latency while __never__ misinterpreting an input due to bounce. Using a significant computational overhead is also undesirable.

## Sampling Theory

At some point, whether it's by a hardware interrupt or software, all input into a micro-processor is going to be polled [3]. So understanding issues related to polling is absolutely necessary while writing any sort of physical facing code, debouncing or otherwise.

When polling analog signals the digital world, the most powerful tool is the `Cardinal Theorem of Interpolation` (aka Nyquist's Theorem) [4]. The theorem roughly states:

> If a signal has a maximum frequency of X hertz, it can be completely determined by sampling every 1 / (2 * X) seconds.

This theorem puts sets the lower bound of the `input width` to twice the period between samples. So if you're polling at 16 mhz you can accurately detect any signals <= 8 mhz, or any input with width longer than 12.5 ns. The sample rate needed to completely determine a signal is referred to as its `Nyquist Rate`. 

As stated in the previous section, the bounce signal/frequency cannot be accurately modeled, so it's not as simple as invoking Nyquist and calling it a day. In order to handle the imperfect model, the concept of a `bounce period` needs to be defined.

## Bounce Period

__Definition:__ The maximum amount of time an input is unstable after a state change.

Inside the bounce period, there is no guarantee that the `Cardinal Theorem of Interpolation` can be applied. Meaning for the bounce period:

- The current state between samples cannot be known.

- The current position inside the bounce period cannot be known.

For example:

![Worst case debounce](https://davepfeiffer.github.io/assets/worst-case-bounce.jpg)
<center>
  <i>In this drawing, the bounce pulses are short enough to fit between each sample causing no state change to be detected until the bounce period is over.</i><br>
</center><br><br>

With the above limitations in mind, two useful assertions can be made:

__1:__

> Given a signal where the only noise is due to bounce and the same state has been sampled over a period longer than the debounce period, the state can be assumed to be stable.

This assertion holds because:

- One or more of the samples must be from outside the bounce period

- The state of the stable sample is known (because they're all the same)

In the best case, every sample during the bounce period is correct and a decision is made right after the bounce period.

In the worse case, every sample during the bounce period is incorrect and a
decision is made after two bounce periods.

Giving a constant:

- ` input_width = 2 * bounce_period + sample_period `

- ` input_delay = 2 * bounce_period + sample_period `

__2:__ 

> Given a signal where the only noise is due to bounce and the state is known to be stable. If the opposite state is sampled, the current state can be safely toggled.

This assertion holds because:

- If the current state is stable, the only way for the opposite state to be sampled is by passing through the debounce period.

- If the debounce period is passed through, the next state must be the opposite of the last stable state.

The quirk with this assertion is that after a state change is detected, the signal needs to be ignored for a bounce period. In the best case, the edge is detected infinitesimally close to input event. In that case, any following samples for the length of the debounce period need to be ignored. 

Because there is no way of knowing if the edge was detected at the beginning of the period, the full debounce period will _always_ need to be ignored. In the worst case, the edge is detected on the sample after leaving the debounce period and another debounce period must be ignored--giving:

- ` input_width = 2 * bounce_period + sample_period `

- ` input_delay = 0 --> bounce_period `

- ` average_input_delay = bounce_period / 2` [5]

_Note:_ Neither of these assertions hold unless the clean signal is being sampled at or above its Nyquist Rate.

---

# Physical Implementation

First off, the bounce time needs to be determined. Any rules of thumb passed around are essentially folk-lore. Physical devices vary drastically and some sort of measurements need to take place for a reasonable amount of confidence.

The two assertions lend themselves to very different strategies:

- Generally, the first assertion will lend itself better for a software polling approach. The strategy has the advantages of being simple to implement and more noise tolerant [6].

- The second assertion translates well to hardware interrupts. Using interrupts will relieve CPU overhead, but will also introduce extra program complexity (interrupts can introduce data races and other concurrency bugs).

The theory covered in these notes should be enough to implement debouncing schemes that inspire confidence. Because good solutions will be heavily dependent on the architecture, I'll leave actual implementations as an exercise for the reader. There are many interesting optimizations that can be made depending on the problem structure. Feel free to send me an email if you have questions, input, or an interesting implementation.

---

# Footnotes

[1] [Wikipedia on Metastability](https://en.wikipedia.org/wiki/Metastability_in_electronics), [ASIC World](http://www.asic-world.com/tidbits/metastablity.html) -- It is very important to be familiar with metastability if you ever deal with flip-flops.

[2] [A Guide to Debouncing, or, How to Debounce a Contact in Two Easy Pages](http://www.ganssle.com/debouncing-pt2.htm) -- A very thorough analysis of bounce in various physical components, definately worth checking out if only for this. There are also some proposed hardware and software solutions. Unfortunately, the software versions weren't particularly attractive and didn't have any supporting theory.

[3] Either you are manually polling in your software or your interrupt manager is polling in hardware (virtually for free). At some point the signal is being latched into a flip-flop.

[4] [Nyquist's Theorem](https://ptolemy.eecs.berkeley.edu/eecs20/week13/nyquistShannon.html)

[5] This assumes a uniform distribution of when the state change is detected. In reality the state change will likely be detected sooner or later depending on the sample rate. Better modeled as an [exponential distribution](https://en.wikipedia.org/wiki/Exponential_distribution) where llambda is some relationship between the sample frequency and specific noise signal.

[6] A blip caused by noise will just make the first approach wait another bounce period before changing state. Noise will cause the second approach to erroneously toggle state and ignore a full debounce period, creating havoc.
